[{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/3-blogstranslated/3.1-blog1/","title":"Blog 1 ","tags":[],"description":"","content":"AWS Partner Network (APN) Blog Unlocking the Power of AI in Manufacturing with PTC Kepware+ on AWS Authors: Preet Virk, Raymond Labbe, Stephen Sponseller, Manish Yashvant\nDate: July 08, 2025\nSource: AWS Public Sector Blog\nTopics: AWS IoT Core, AWS IoT SiteWise, Industrial IoT Solutions\nIntroduction Manufacturers face fragmented systems, legacy devices, and incompatible industrial protocols that create data silos. This slows innovation and increases cybersecurity risk.\nOrganizations are now racing to modernize operations and use AI-driven insights.\nThe collaboration between PTC Kepware and AWS aims to solve these industrial connectivity challenges.\nThis blog explains how Kepware+ integrated with AWS can improve operational efficiency, reduce costs, and enhance industrial analytics.\nWhy Industrial Connectivity Matters Factories use numerous sensors, controllers, and machines communicating through different protocols, making data collection difficult.\nKepware+ with AWS provides:\nStandardized data access from PLCs, SCADA, HVAC, and sensors Real-time AI workflows via AWS IoT Core / AWS Greengrass Predictive analytics powered by AWS IoT SiteWise and Amazon SageMaker This leads to reduced downtime, improved asset efficiency, and increased operational visibility.\nReal-World Impact 1. Predictive Maintenance A global automotive manufacturer achieved:\n40% reduction in unplanned downtime $2.8M annual savings By:\nCollecting data from 15 factories into Amazon S3 Running analytics with AWS IoT SiteWise + Amazon SageMaker 2. Wind Energy Analytics A renewable energy provider:\nConnected 2,200 wind turbines Streamed encrypted data to AWS IoT Core Analyzed performance using Redshift + S3 Data Lake Results:\n15% increase in turbine performance 50% reduction in operational costs 3. Energy Optimization in Oil \u0026amp; Gas Using:\nKepware+ for data acquisition AWS IoT Core for data pipelines AWS IoT SiteWise + QuickSight for analysis Outcome:\n15% reduction in overall energy consumption 4. Supply Chain Optimization A food \u0026amp; beverage manufacturer:\nImproved supply chain visibility by 30% Reduced product waste Increased on-time delivery performance 5. Smart Building Management Kepware+ converts legacy protocols such as:\nBACnet Modbus OPC Data flows into AWS IoT Core, enabling dashboards through Amazon QuickSight.\n6. Pharmaceutical Tracking \u0026amp; Compliance For strict regulatory environments:\nData stored securely in Amazon S3 with encryption \u0026amp; versioning AWS IoT SiteWise + Amazon Athena detect anomalies Supports FDA audit and compliance requirements How Kepware+ Works with AWS Kepware+ enhances communication between industrial equipment and AWS services.\nKey capabilities include:\nConnectivity to PLCs, SCADA, sensors using Kepware’s driver library Supports secure MQTT communication Centralized configuration management Real-time data ingestion to AWS IoT SiteWise through Greengrass AWS IoT Core integration via MQTT Client Agent AI/ML workflows with Amazon SageMaker ETL pipelines using AWS Glue Data querying with Athena, storage in Redshift / Neptune / S3 Event-driven integrations using AWS Lambda Turning Isolated Data into Actionable Insights Kepware+ + AWS provides:\nSimplified OT data access Enhanced security with Greengrass Global scalability Faster adoption of industrial AI Organizations can scale from individual production lines to global operations.\nConclusion Manufacturing is rapidly evolving, requiring:\nConnectivity Intelligence Flexibility The combination of Kepware+ and AWS enables:\nPredictive maintenance Energy optimization Compliance management Supply chain resilience PTC – A Leading AWS IoT Partner PTC is an AWS IoT Competency Partner and provides the ThingWorx industrial platform.\nContact PTC | Partner Overview | AWS Marketplace\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"AWS Public Sector Blog Building Resilient Healthcare Systems Through Cloud Computing Authors: Justin Bowden, Andrew Wiltshire, Senthil Gurumoorthi\nDate: 08 JUL 2025\nSource: AWS Public Sector Blog\nSummary The resilience of clinical and operational healthcare systems is not just a technical matter but also an important policy priority. Even short-term disruptions to electronic health records or clinical systems can directly affect patient care and safety.\nAWS has released the guide “Resilient Healthcare Through Cloud Computing: A Strategy and Policy Guide”, which provides a comprehensive framework to enhance healthcare system resilience, ensure regulatory compliance, and improve patient outcomes.\nWhy Cloud Resilience Matters in Healthcare Healthcare organizations operate in environments where system reliability directly impacts patient safety.\nThe growth of:\nElectronic Health Records (EHR) Telehealth Connected medical devices (IoMT) … has created complex technological ecosystems requiring high performance, strong security, and exceptional resilience.\nThe AWS guide introduces key principles:\nAutomated system recovery when thresholds are exceeded Regularly validated procedures to ensure effective recovery Distributed architectures to improve scalability and reduce single points of failure Cloud Advantages for Healthcare AWS cloud infrastructure offers capabilities that traditional on-premises systems struggle to match, such as:\nMultiple Regions and Availability Zones (AZs) Workload distribution across physically separate locations while maintaining high performance Automated improvements in security, efficiency, and disaster recovery Below are real-world examples:\n1. Tufts Medicine – Epic EHR deployment on AWS in 14 months Migrated full EHR environment (production, DR, training) to AWS Consolidated technology stacks and modernized applications Became the first healthcare system to run a complete Epic environment on AWS\n→ Result: better performance and improved experience for patients and providers. 2. Baptist Memorial Health Care (BMHC) Serving 3 million patients across three U.S. states.\nPartnered with AWS Partner Optimum Healthcare IT Migrated EHR to AWS to overcome on-premise limitations Achieved 20% performance improvement Lower total cost of ownership Stronger disaster recovery across 22 hospitals + 200 clinics 3. NSW Health – 10× performance improvement Enterprise patient record application ran 10 times faster 70% reduction in critical incidents Application deployment improved by 50% Environment provisioning reduced from 6–8 weeks → under 4 hours USD 16 million in financial benefits Saved 144,000 work hours for frontline clinicians Integrated: AWS Security Hub Amazon GuardDuty\n→ Automated security checks and early threat detection Building a Resilience Framework The guide recommends steps such as:\nIdentify critical workloads Set appropriate RTO and RPO Apply the shared responsibility model Deploy applications across multiple AZs Build comprehensive disaster recovery strategies Maintain compliance with healthcare regulations Policy Recommendations for Healthcare Leaders AWS advises policymakers to:\nEstablish cloud-first policies for health systems Create financial incentives to support digital transformation Adopt international standards rather than fragmented requirements Promote resilience excellence frameworks Develop cloud-focused healthcare workforce training Build regulatory sandboxes for testing innovative cloud solutions Ready to Strengthen Your Healthcare System’s Resilience? Download the full guide:\n“Resilient Healthcare Through Cloud Computing: A Strategy and Policy Guide”\nOr contact AWS experts for further consultation.\nAuthor Profiles Justin Bowden Compliance \u0026amp; Security Assurance Principal – AWS Supports ANZ agencies in enhancing cloud resilience Expertise: risk management, security, operational resilience Andrew Wiltshire Head of Healthcare Public Policy – AWS APJ 40 years of healthcare experience Enthusiast of classic cars and 4x4 off-road vehicles Senthil Gurumoorthi Principal – AWS Leads data governance initiatives Co-author of ISPE GAMP 5 V2 Member of FDA-Industry CSA Team "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Artificial Intelligence Building a Just-in-Time Knowledge Base with Amazon Bedrock Author: Steven Warwick\nDate: 07 JUL 2025\nSource: Amazon Bedrock, Amazon Bedrock Knowledge Bases, Cloud Cost Optimization, AI, SaaS\nSummary Multi-tenant SaaS systems often need to process a large volume of documents, but traditional RAG approaches consume excessive resources because they ingest and store embeddings for documents that may never be queried.\nThe Just-in-time Knowledge Base architecture solves these challenges by:\nProcessing documents only when needed (on-demand ingestion) Automatically removing unused data using DynamoDB TTL Reducing OpenSearch Serverless costs Supporting multi-tenant isolation and strong data separation Enabling tier-based pricing depending on tenant configuration This solution allows SaaS providers to scale flexibly, reduce operational overhead, and maintain high query performance.\nArchitecture Overview The solution uses the following AWS services:\nAmazon Bedrock – Document processing, querying, and RAG content generation Amazon OpenSearch Serverless – Vector indexing and search Amazon S3 – Storing raw files Amazon DynamoDB – Storing metadata, TTL, and tenant document tracking AWS Lambda – Automatically cleaning expired documents AWS CDK – Infrastructure provisioning These components work together to ensure only necessary documents are ingested, while outdated data is automatically removed.\nWorkflow 1. User login and tenant assignment When a user logs in, the system assigns a tenantId to define the data boundary and access scope.\n2. Create a project Each project contains a list of files the user wants to query.\nThe system initializes metadata linking user – tenant – project.\n3. Upload files Users upload files via pre-signed URLs.\nFiles are stored in S3 and metadata is recorded in DynamoDB.\n4. Just-in-time ingestion Documents are only ingested into the Knowledge Base when the user starts chatting with the project.\nEach file receives a TTL based on the tenant’s subscription tier.\n5. Refreshing TTL during queries Frequently-queried documents → TTL is extended → remain active.\nUnused documents → TTL expires → removed automatically.\n6. Automatic document deletion DynamoDB Streams detect TTL expiration → Lambda deletes the document from the Knowledge Base and OpenSearch.\nExample: Ingesting tenant-specific TTL documents # Ingesting files with tenant-specific TTL values def ingest_files(user_id, tenant_id, project_id, files): tenants = json.loads(os.environ.get(\u0026#39;TENANTS\u0026#39;))[\u0026#39;Tenants\u0026#39;] tenant = find_tenant(tenant_id, tenants) ttl = int(time.time()) + (int(tenant[\u0026#39;FilesTTLHours\u0026#39;]) * 3600) for file in files: file_id = file[\u0026#39;id\u0026#39;] s3_key = file.get(\u0026#39;s3Key\u0026#39;) bucket = file.get(\u0026#39;bucket\u0026#39;) knowledge_base_files_table.put_item( Item={ \u0026#39;id\u0026#39;: file_id, \u0026#39;userId\u0026#39;: user_id, \u0026#39;tenantId\u0026#39;: tenant_id, \u0026#39;projectId\u0026#39;: project_id, \u0026#39;documentStatus\u0026#39;: \u0026#39;ready\u0026#39;, \u0026#39;createdAt\u0026#39;: int(time.time()), \u0026#39;ttl\u0026#39;: ttl } ) Nếu bạn muốn mình dịch ngắn hơn, dịch kiểu academic, dịch kiểu technical A "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.7-security/5.7.1-s3-cloudfront/","title":"Configure S3 &amp; CloudFront","tags":[],"description":"","content":"1. Create S3 Bucket:\nCreate Bucket (Ex: minimarket-assets-prod) Block Public Access: On Manually upload images folder from code to this Bucket 2. Create CloudFront Distribution:\nOrigin type: Select Elastic Load Balancer Origin Domain: Select Load Balancer of Beanstalk Settings: Select Customize origin settings Protocol: HTTP Only Cache settings: Select Customize cache settings Viewer Protocol Policy: Redirect HTTP to HTTPS 3. Add S3 Origin (To retrieve images):\nGo to newly created Distribution Go to Origins tab \u0026gt; Create Origin Origin domain select the S3 created earlier (minimarket-assets-prod) Origin Access: Select Origin access control (OAC) \u0026gt; Create new OAC Bucket Policy: Copy policy provided by CloudFront and paste into S3 Bucket policy 4. Configure Behavior:\nReturn to CloudFront go to Behaviors tab Create Behavior with Path pattern: /images/ Point to Origin S3 Cache Policy: CachingOptimized "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.6-cicd/5.6.1-codebuild/","title":"Create Build Project","tags":[],"description":"","content":" Access CodeBuild \u0026gt; Create project\nProject name: MiniMarket-Build\nSource: Select GitHub (Connect to Repo containing code)\nEnvironment:\nEnvironment image: Managed Image Operating system: Amazon Linux Runtime: Standard Image: 5.0 Service role: New service role Privileged: Enable (Required to run Docker build commands) Buildspec: Use a buildspec file\nClick Create build project\nAfter creation is complete, go to IAM Role of the newly created CodeBuild, grant additional permission AmazonEC2ContainerRegistryPowerUser so it can push images to ECR\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.3-network/5.3.1-create-vpc/","title":"Create VPC &amp; Subnets","tags":[],"description":"","content":" Open Amazon VPC console (Note: Choose region suitable for needs, here the group uses Region ap-southeast-1) Select Create VPC Configuration: Name: MiniMarket-VPC IPv4 CIDR: 10.0.0.0/16 Create Subnets (Split 2 AZs to ensure High Availability): Public Subnets (2): 10.0.1.0/24 \u0026amp; 10.0.2.0/24 (Used for Load Balancer \u0026amp; NAT) Private Subnets (2): 10.0.3.0/24 \u0026amp; 10.0.4.0/24 (Used for App, DB, Redis) Click Create VPC and wait for state to change to Available is successful "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"“AWS Cloud Day 2025” Report Event Purpose Update cloud technology trends in key industries (Finance, Banking). Understand modern data strategies to support Generative AI. Grasp application modernization models on AWS. Highlights Financial Services \u0026amp; Modernization Dissolving boundaries: The trend of bridging the gap between Business and IT in financial institutions. Technology is a business driver, not just support. Modernization: Banks and payment organizations are shifting to Cloud for agility and customer experience. Data Analytics \u0026amp; GenAI Data Strategy: Data is fuel for AI. A solid data strategy is required before applying Generative AI. Integration: Integrating Foundation Models into data analytics workflows to improve decision-making effectiveness. Migrate, Modernize, and Build on AWS Cloud-native Architectures: Shifting from Monolith to Microservices and Serverless. Workload Modernization: Strategies for migrating and optimizing legacy applications on modern AWS platforms. What I Learned Modernization Mindset: Understanding that \u0026ldquo;moving to cloud\u0026rdquo; isn\u0026rsquo;t just moving servers, but re-architecting to Cloud-native to leverage scalability. Importance of Data: Generative AI is only effective with clean and well-organized data. Application to Work Apply Cloud-native thinking to the MiniMarket project (using Docker, Managed Services like RDS/ElastiCache instead of self-hosted on EC2). Consider data strategy for future scalable features (e.g., analyzing purchasing behavior). "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Hồ Chí Kiệt\nPhone Number: 0818227828\nEmail: kiethcse182293@fpt.edu.vn\nUniversity: FPT University Ho Chi Minh Campus\nMajor: Software Engineer\nClass: AWS082025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 12/08/2025 to 12/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.1-workshop-overview/","title":"Introduction","tags":[],"description":"","content":"Introduction MiniMarket is an e-commerce application built on the .NET Core platform, applying modern 3-Tier Architecture. The goal of this Workshop is to re-platform the application from an On-premise environment to AWS cloud infrastructure (Cloud Native Migration) ensuring AWS Well-Architected Framework criteria: Security, Reliability, Performance Efficiency, and Cost Optimization Workshop Overview Solution Architecture:\nCompute: Use AWS Elastic Beanstalk (Docker platform) to simplify deployment, infrastructure management, and Auto Scaling Database: Amazon RDS for SQL Server deployed in Private Subnet to ensure data security Caching: Amazon ElastiCache (Redis) helps store User Sessions and offload Database queries, increasing response speed Network \u0026amp; Security: VPC: Designed with Public/Private Subnet model combined with NAT Gateway Application Layer Security: Use AWS WAF combined with Amazon CloudFront to protect against Web attacks and distribute content globally Storage: Amazon S3 used to store and serve static assets (product images) with high durability DevOps: Fully automated CI/CD process with AWS CodePipeline and CodeBuild Monitoring: Amazon CloudWatch to monitor system health (CPU, Network) and send alerts "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.8-monitoring/5.8.1-cloudwatch/","title":"Monitoring with CloudWatch","tags":[],"description":"","content":" Create SNS Topic:\nGo to SNS \u0026gt; Topics \u0026gt; Create Topic Type: Standard Name: DevOps-Alerts Create Subscription\nCreate Subscription \u0026gt; Protocol: Email \u0026gt; Enter your email (Remember to Confirm mail) Create CPU Alarm:\nGo to CloudWatch \u0026gt; Alarms \u0026gt; Create alarm Select metric \u0026gt; EC2 \u0026gt; Per-Instance Metrics \u0026gt; Select InstanceID of Beanstalk \u0026gt; CPUUtilization Condition: CPUUtilization: Greater than 70% Notification: Select Topic DevOps-Alerts Create Alarm. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.5-app/5.5.1-dockerize/","title":"Package with Docker","tags":[],"description":"","content":"Before moving to Cloud, we need to package the .NET Core application into a Docker Image\nCreate Dockerfile: At the root directory of the Solution, create a file named Dockerfile (no extension) ```dockerfile # STAGE 1: BUILD FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build WORKDIR /src COPY [\u0026quot;MiniMarket.sln\u0026quot;, \u0026quot;./\u0026quot;] COPY [\u0026quot;WebShop/WebShop.csproj\u0026quot;, \u0026quot;WebShop/\u0026quot;] # ... (Copy other projects if any) RUN dotnet restore \u0026quot;MiniMarket.sln\u0026quot; COPY . . WORKDIR \u0026quot;/src/WebShop\u0026quot; RUN dotnet build \u0026quot;WebShop.csproj\u0026quot; -c Release -o /app/build RUN dotnet publish \u0026quot;WebShop.csproj\u0026quot; -c Release -o /app/publish # STAGE 2: RUNTIME FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS final COPY --from=build /app/publish . WORKDIR /app EXPOSE 8080 ENTRYPOINT [\u0026quot;dotnet\u0026quot;, \u0026quot;WebShop.dll\u0026quot;] ENV ASPNETCORE_URLS=http://+:8080 ENV ASPNETCORE_ENVIRONMENT=Development ``` Create buildspec.yml: Create file buildspec.yml to instruct AWS CodeBuild how to package and push to ECR ```yaml version: 0.2 phases: pre_build: commands: - echo Logging in to Amazon ECR... # --- INFORMATION CONFIGURATION --- - AWS_DEFAULT_REGION=ap-southeast-1 # Replace your Account ID in the line below: - AWS_ACCOUNT_ID= YOUR ACCOUNT ID - IMAGE_REPO_NAME=market-app - IMAGE_TAG=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7) - REPOSITORY_URI=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME # --------------------------- - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com build: commands: - echo Build started on `date` - echo Building the Docker image... - docker build -t $REPOSITORY_URI:latest . - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$IMAGE_TAG post_build: commands: - echo Build completed on `date` - echo Pushing the Docker image... - docker push $REPOSITORY_URI:latest - docker push $REPOSITORY_URI:$IMAGE_TAG - echo Writing image definitions file... # Automatically create Dockerrun.aws.json configuration file for Beanstalk # Map Port 80 (Host) to 8080 (Container .NET) - printf '{\u0026quot;AWSEBDockerrunVersion\u0026quot;:\u0026quot;1\u0026quot;,\u0026quot;Image\u0026quot;:{\u0026quot;Name\u0026quot;:\u0026quot;%s\u0026quot;,\u0026quot;Update\u0026quot;:\u0026quot;true\u0026quot;},\u0026quot;Ports\u0026quot;:[{\u0026quot;ContainerPort\u0026quot;:8080,\u0026quot;HostPort\u0026quot;:80}]}' \u0026quot;$REPOSITORY_URI:$IMAGE_TAG\u0026quot; \u0026gt; Dockerrun.aws.json - cat Dockerrun.aws.json artifacts: files: - Dockerrun.aws.json ``` "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.9-cleanup/5.9.1-cleanup/","title":"Resource Cleanup","tags":[],"description":"","content":"To avoid unexpected costs after completing the Workshop, delete resources in the following correct order:\nNAT Gateway: Delete NAT Gateway \u0026gt; Wait for Deleted \u0026gt; Release Elastic IP (Most important as it costs the most) Elastic Beanstalk: Terminate Environment ElastiCache: Delete Redis Cluster (Uncheck Create Backup) RDS: Stop (or Delete if no longer in use - remember to uncheck Final Snapshot). WAF: Manage resources \u0026gt; Disassociate \u0026gt; Delete protection pack (web ACL) S3: Empty and Delete Bucket (Can skip deleting if still in use as cost is not too high)\nCloudFront Disable and Delete\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.4-data/5.4.1-security-groups/","title":"Set up Security Groups","tags":[],"description":"","content":" Access EC2 \u0026gt; Security Groups \u0026gt; Create security group Group 1: Web Server (sg-web-app) Description: Allow HTTP from Internet Inbound Rules: Type: HTTP (80) | Source: 0.0.0.0/0 (Or only from Load Balancer if wanting stricter security) Group 2: Database (sg-db-sql) Description: Allow access only from Web Server Inbound Rules: Type: MSSQL (1433) | Source: Custom \u0026gt; Select ID of sg-web-app Group 3: Redis Cache (sg-redis-cache) Description: Allow access only from Web Server Inbound Rules: Type: Custom TCP (6379) | Source: Custom \u0026gt; Select ID of sg-web-app "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members\n- Read and take note of internship unit rules and regulations 08/09/2025 08/09/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database - Learn to draw AWS architecture on draw.io - How to do AWS workshop 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/watch?v=l8isyDe-GwY\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=2 https://www.youtube.com/watch?v=mXRqgMr_97U\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i\u0026index=3 4 - Create new AWS Account - Manage usage costs on AWS with AWS Budgets - Request support with AWS Support -Practice: + Set up the first AWS account, enable MFA, create Admin group/user, configure the Console, and manage Support Cases + Create a budget by template, including Cost Budget, Usage Budget, RI Budget, and Savings Plans Budget. + Change the support package and create a support request. 10/09/2025 10/09/2025 https://000001.awsstudygroup.com/ https://000007.awsstudygroup.com/ https://000009.awsstudygroup.com/ 5 - Access Management with AWS Identity and Access Management (AWS IAM) - Deploy network infrastructure with Amazon Virtual Private Cloud (Amazon VPC) + Firewall in VPC + Deploying Amazon EC2 Instances + Setting Up Site-to-Site VPN Connection in AWS Practice: + Create a VPC with subnet, internet gateway, route table, security group, EC2 server, NAT gateway, and a VPN environment. 11/09/2025 11/09/2025 https://000002.awsstudygroup.com/ https://000003.awsstudygroup.com/ 6 - Getting Started and Deploying Applications on Amazon Compute Cloud (Amazon EC2) + Launch Microsoft Windows Server 2022 Instance + Deploying an AWS User Management Application on Amazon Linux 2 + Deploying Node.js Applications on Amazon EC2 Windows + Cost \u0026amp; Usage Governance with IAM - Grant application permissions to access AWS services through IAM Role (AWS IAM) -Practice: + Connect to Windows Server 2022 and Amazon Linux instances, install LAMP/XAMPP web servers, and implement cost governance with AWS IAM. + Create S3 bucket 12/09/2025 12/09/2025 https://000004.awsstudygroup.com/ https://000048.awsstudygroup.com/ Week 1 Achievements Orientation \u0026amp; Onboarding Got acquainted with FCJ members Read and noted internship unit rules and regulations Understanding AWS Fundamentals Learned about AWS and its main service groups: Compute, Storage, Networking, Database Practiced drawing AWS architectures using draw.io Explored AWS workshops through study group resources and video tutorials Account Setup \u0026amp; Cost Management Successfully created and configured an AWS Free Tier account Enabled Multi-Factor Authentication (MFA) for enhanced security Created Admin group and Admin user, and configured access through the AWS Management Console Practiced managing costs using AWS Budgets: Cost Budget Usage Budget RI Budget Savings Plans Budget Changed the AWS support package and created support requests Gained experience in Support Case management with AWS Support IAM \u0026amp; VPC Deployment Practiced Access Management with AWS Identity and Access Management (IAM) Deployed network infrastructure with Amazon VPC: Created subnet, internet gateway, route table, and security groups Launched EC2 instances inside VPC Configured NAT Gateway and set up a Site-to-Site VPN connection EC2 \u0026amp; Application Deployment Launched and connected to Microsoft Windows Server 2022 and Amazon Linux 2 instances Installed and configured LAMP on Linux and XAMPP on Windows Deployed test applications including Node.js on Amazon EC2 Implemented cost and usage governance using IAM policies and roles Granted application permissions to access AWS services through IAM Roles Successfully created and managed S3 buckets for storage "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Week 1: Getting familiar with AWS and basic AWS services\nWeek 2: Understand Amazon S3 static website hosting and how to accelerate websites with Amazon CloudFront. Week 3: Explore AWS credit system and cost management practices.\nWeek 4: Learn and practice Serverless Automation using AWS Lambda to optimize EC2 operation costs. Week 5: Translate the blog of AWS, Build the database of project\nWeek 6: Begin setting up the MVC structure for the project.\nWeek 7: Review academic subjects for the upcoming midterm exam on 31/10/2025.\nWeek 8: Focus on studying and completing the midterm exam on 31/10/2025.\nWeek 9: Understand ASP.NET Core middleware and filters for request processing.\nWeek 10: Connect MVC Controllers and Views with the database using Entity Framework Core.\nWeek 11: Learn Docker fundamentals and containerization concepts.\nWeek 12: Add static product images stored locally for display in the project.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Learn and practice using AWS Cloud9 for cloud-based development. Understand Amazon S3 static website hosting and how to accelerate websites with Amazon CloudFront. Learn to scale applications with EC2 Auto Scaling. Gain hands-on experience with Amazon CloudWatch for monitoring and alerting. Explore Hybrid Networking \u0026amp; Directory Service Integration. Practice Infrastructure deployment \u0026amp; automation with AWS CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Cloud Development with AWS Cloud9 + Using Cloud9 Basic Features (command line, text files) + Using AWS CLI - Static Website Hosting with Amazon S3 + Understanding S3 Buckets vs Objects + Enable static website feature + Configure public access block + Configuring public objects + Accelerate with CloudFront + Multi-Region Replication Practice: + Create Cloud9 instance + Create \u0026amp; configure S3 bucket + Test CloudFront distribution 15/09/2025 15/09/2025 https://000049.awsstudygroup.com/ https://000057.awsstudygroup.com/ 3 - Scaling Applications with EC2 Auto Scaling + Amazon EC2 Auto Scaling concepts + AMIs and Launch Templates + Setting Up Load Balancer + Business/technical need for Auto Scaling Practice: + Create Launch Template + Create Target Group + Create Load Balancer + Create Auto Scaling Group 16/09/2025 16/09/2025 https://000006.awsstudygroup.com/ 4 - Monitoring with Amazon CloudWatch + Preparatory steps + CloudWatch Metrics + CloudWatch Logs + CloudWatch Alarms + CloudWatch Dashboards Practice: + Collect EC2 metrics + Enable \u0026amp; view logs + Create Alarms + Build Dashboard 17/09/2025 17/09/2025 https://000008.awsstudygroup.com/ 5 - Hybrid Networking \u0026amp; Directory Service Integration + Prerequisites for hybrid connectivity + Connect via Direct Connect / VPN / Transit Gateway + Set up Active Directory (AD) integration + Configure Hybrid DNS Practice: + Configure hybrid connectivity + Connect on-premise-like environment via Transit Gateway + Deploy Directory Service (AD) + Set up Hybrid DNS 18/09/2025 18/09/2025 https://000010.awsstudygroup.com/ 6 - Infrastructure Deployment \u0026amp; Automation with CLI + Install \u0026amp; configure AWS CLI + Deploy infrastructure (VPC, Subnets, Gateways, Security Groups) + Manage S3 buckets \u0026amp; objects + Use SNS for notifications + Configure IAM + Launch EC2 instances + Troubleshoot issues Practice: + Install CLI \u0026amp; verify setup + Deploy infra via CLI + Create S3 bucket + Configure SNS topic \u0026amp; subscription + Apply IAM policies + Launch EC2 \u0026amp; test connectivity + Troubleshoot network/instance errors 19/09/2025 19/09/2025 https://000011.awsstudygroup.com/ Week 2 Achievements Day 2 – Cloud9 \u0026amp; S3 Website Hosting Worked with Cloud9 IDE (command line, text files). Installed \u0026amp; tested AWS CLI. Configured S3 bucket for static website hosting. Enabled public access block and object permissions. Integrated \u0026amp; tested CloudFront. Practiced multi-region replication. Day 3 – EC2 Auto Scaling Learned Auto Scaling concepts for availability \u0026amp; cost efficiency. Understood AMIs \u0026amp; Launch Templates. Configured Application Load Balancer and Target Groups. Practice: created Launch Template, Target Group, Load Balancer, Auto Scaling Group. Day 4 – CloudWatch Monitoring Learned CloudWatch Metrics, Logs, Alarms, Dashboards. Collected EC2 metrics and enabled logs. Created Alarms to trigger alerts. Built a CloudWatch Dashboard for visualization. Day 5 – Hybrid Networking Learned Direct Connect, VPN, Transit Gateway. Set up Active Directory (AD) in AWS. Configured Hybrid DNS for cross-environment resolution. Practice: hybrid connectivity + AD integration + DNS setup. Day 6 – Infrastructure Automation Installed and configured AWS CLI. Deployed infra resources (VPC, subnets, gateways, SGs) via CLI. Created \u0026amp; configured S3 bucket. Configured SNS for notifications. Applied IAM policies \u0026amp; roles. Launched EC2 instance and tested connectivity. Practiced troubleshooting common AWS infra issues. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.3-network/5.3.2-gateways/","title":"Configure Internet &amp; NAT Gateway","tags":[],"description":"","content":"Create Internet Gateway In the VPC dashboard click on Internet gateways Then click on Create internet gateway In the Internet gateway creation section, name it as desired then click on Create internet gateway and wait for it to be created After the Internet gateway is finished creating go to Actions and click on Attach to VPC to attach it to the VPC created in the previous section Create NAT Gateway Create NAT Gateway placed in Public Subnet 1 Assign Elastic IP to have a static address to the Internet "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.3-network/5.3.3-routing/","title":"Configure Route Table","tags":[],"description":"","content":"Create Route Table Click on Route tables section in VPC dashboard\nCreate 2 Route Tables, Public with Private\nPublic Route Table: For Public Route Table, in Routes section click Edit routes Point 0.0.0.0/0 to Internet Gateway And in Subnet associations section, assign to both Public Subnets Private Route Table: For Private Route Table, we will point 0.0.0.0/0 to NAT Gateway And in Subnet associations section, assign to both Private Subnets Separating Route Tables ensures that Databases in Private Subnet are never exposed directly to the Internet.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"“Data Science on AWS Workshop” Report Event Purpose Hands-on experience with AWS AI/ML services. Learn the data preparation and Machine Learning model building process with Low-code/No-code tools. Highlights AI Services Exploration Amazon Textract: Intelligent service for extracting text and data from scanned documents (OCR). Amazon Polly: Service that converts text into lifelike speech (Text-to-Speech). Data Prep \u0026amp; Modeling Amazon SageMaker Canvas: No-code tool helping Business Analysts build ML models visually. SageMaker Processing: Handling and cleaning data at scale. SageMaker Studio: Comprehensive Integrated Development Environment (IDE) for Machine Learning, from building, training to deploying models. What I Learned AI vs ML Distinction: Clearly understood the difference between using pre-trained AI services (like Polly, Textract) and building custom ML models on SageMaker. Low-code ML: Recognized the democratization of Machine Learning, enabling non-coders to generate value from data thanks to SageMaker Canvas. Application to Work Potential to integrate Amazon Polly into MiniMarket project to read product information for visually impaired users (Accessibility). Use Textract to automate input invoice data entry for the inventory management system. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.4-data/5.4.2-rds/","title":"Initialize Amazon RDS","tags":[],"description":"","content":" Access RDS Console \u0026gt; Subnet groups \u0026gt; Create DB subnet group Name: db-private-group Subnets: Select 2 AZs and select exactly 2 Private Subnets Go to Databases \u0026gt; Create database Engine options: Microsoft SQL Server (Express Edition) Templates: Free tier Settings: Set Master Password (remember for later use) Connectivity: VPC: VPC you created for Web Subnet group: db-private-group Public access: No VPC security group: Select Security group you created for database Click Create database "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.5-app/5.5.2-beanstalk-setup/","title":"Initialize Elastic Beanstalk","tags":[],"description":"","content":"We will create an environment to run the application\nAccess Elastic Beanstalk \u0026gt; Create application App Name: MiniMarket-App Platform: Docker (Amazon Linux 2023) Application code: Select Sample application (To test infrastructure first) Network Configuration (Networking) - Extremely Important: VPC: Select the VPC you created for MiniMarket Instance settings: Public IP address: Uncheck Subnets: Select 2 Private Subnets EC2 security groups: Select sg-web-app Capacity: Environment type: Select Load balanced Load balancer network settings: Visibility: Public Subnets: Select 2 Public Subnets Click Create. The system will take about 5-7 minutes to initialize "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.2-prerequiste/","title":"Prerequisites","tags":[],"description":"","content":"IAM permissions Attach AdministratorAccess in IAM permission policy to the AWS account for easier workflow Note: Using Administrator privileges is recommended only for the Workshop environment to ensure the deployment process is uninterrupted. In a real Production environment, adhere to the Least Privilege principle for each service { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Source Code GitHub repository containing .NET Core code and a valid Dockerfile "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Digital Transformation for Mini-market on AWS Cloud Platform .NET 3-tier E-commerce Solution applying Repository and Unit of Work Pattern 1. Executive Summary This proposal presents an end-to-end solution for \u0026ldquo;Digital Transformation for Mini-market on AWS Cloud Platform\u0026rdquo;. Traditional mini-markets are currently facing three major challenges: (1) Manual inventory management (using Excel/notebooks) causing revenue loss and resource waste; (2) 100% dependence on offline sales channels, missing the growing e-commerce market and losing competitiveness; and (3) Slow operational processes (such as manual price lookup), resulting in poor customer experience.\nThe group\u0026rsquo;s solution is to build a comprehensive e-commerce and operations management platform. Regarding software architecture, the group will use .NET 3-tier architecture (ASP.NET Core MVC, EF Core) combined with Repository Pattern and Unit of Work Pattern. Regarding infrastructure architecture, it is designed according to the AWS Well-Architected Framework, running on AWS Elastic Beanstalk (for .NET backend), Amazon RDS for SQL Server (for database), and Amazon S3 (for static assets). The system is performance-optimized using CloudFront and ElastiCache, and secured using WAF, VPC, and NAT Gateway. The deployment process is fully automated using a CI/CD pipeline integrated with GitHub.\nBusiness benefits are immediate, including automated inventory management (reducing loss) and opening a new online revenue channel. Regarding investment, infrastructure costs in the first 12 months are nearly zero by leveraging AWS Free Tier (e.g., RDS Express Edition, EC2 t3.micro). Long-term operating costs (after Free Tier) are also very practical, estimated at around 138.06 USD/month for the entire system. With minimal initial investment and the ability to directly solve problems causing revenue loss, ROI is very high and almost instant.\nThe project is proposed to be implemented in 12 weeks, divided into 4 main phases: (1) Foundation \u0026amp; Architecture, (2) Core Feature Development, (3) AWS Integration \u0026amp; CI/CD, and (4) Finalization \u0026amp; Deployment. Expected results are measured by specific success metrics: reduce inventory errors by 90%, reduce checkout time by 50%, and achieve 20% revenue from online channels in the first 6 months. This solution not only solves immediate problems but also provides mini-markets with a scalable platform for data-driven decision-making in the future.\n2. Problem Statement Current Problem\nSmall and medium retail businesses, especially the traditional \u0026ldquo;mini-market\u0026rdquo; model in Vietnam, are operating based on outdated manual processes. In the context of an increasingly digitized market, failing to apply technology to the work environment has created several problems, directly affecting their survival and growth.\nKey Problems\nManual inventory management leads to inaccuracy in figures and resource waste: Most mini-markets currently manage thousands of product codes (SKUs) using notebooks or Excel files. Importing/exporting goods and end-of-day inventory checks rely entirely on manual counting and entry. This can lead to data errors because the manual entry process is prone to mistakes, typically product codes and quantities, causing significant discrepancies between \u0026ldquo;on book\u0026rdquo; data and \u0026ldquo;actual\u0026rdquo; stock. Checking goods manually like this also demands high resources as staff have to spend hours every day counting, reconciling, and correcting reports, instead of focusing on sales or customer service. Finally, financial loss occurs; when data is not entered accurately, store owners cannot control the condition of goods such as expired goods, damaged goods, or theft, leading to a loss of 5-10% of inventory value monthly. Dependence on offline sales, missing the E-commerce market: Typically, mini-markets in Vietnam mostly depend on walk-in customers (offline). They are also limited by geographical location (only serving the local area) and a familiar customer base. Stores like this stand outside the E-commerce market, missing the young customer base already accustomed to online shopping. They cannot compete on convenience such as 24/7 ordering or door-to-door delivery compared to large convenience store chains like Circle K or 7-Eleven and delivery apps like Grab and Shopee, leading to a risk of losing customers over time. Operational and customer experience issues: The payment and information lookup process in traditional mini-markets is usually very slow. When customers ask about price, product information, or promotions, staff (especially new staff) have to manually look up in notebooks, leading to wasted time. Making customers wait long for information lookup or checkout creates frustration and unprofessionalism. Staff waste too much time on simple, error-prone tasks (such as misreading prices due to bad handwriting), reducing the number of customers that can be served during peak hours. 3. Solution Architecture The architecture is designed to solve the stated problems by combining .NET 3-tier software architecture with AWS Managed Services. This architecture adheres to the principles of the AWS Well-Architected Framework, ensuring security, high performance, fault tolerance, and cost optimization.\nAWS Services Used\nAWS Elastic Beanstalk: PaaS (Platform as a Service) selected to deploy the .NET 3-tier application (including WebShop Presentation Layer and Application Services Layer). Beanstalk automates 100% of infrastructure management, including automatically creating Auto Scaling Group (ASG) to ensure scalability and cost savings.\nAmazon RDS (SQL Server): Database Service (Managed Relational Database Service) to host the Persistence Layer. SQL Server was chosen because the group\u0026rsquo;s .NET application was developed and optimized for SQL Server. Using RDS for SQL Server allows migrating the application to AWS without changing code in the Data Layer. RDS will also automate complex tasks such as daily backups, patching, and failover. regarding security, RDS is placed in a Private Subnet, inaccessible directly from the Internet, only allowing the application on Beanstalk to connect. And regarding cost optimization, to optimize costs in the initial phase, we can start with SQL Server Express Edition on RDS, this version is within the AWS Free Tier.\nAmazon S3: Object Storage Service. Used to store static assets such as product images, CSS files, and JavaScript. S3 provides extremely low cost and unlimited scalability.\nAmazon CloudFront: Content Delivery Network Service - CDN. CloudFront caches static files from S3 at servers (Edge Locations) globally, helping users load pages significantly faster. It helps reduce direct load on Beanstalk servers and helps the .NET application focus on processing logic.\nAmazon WAF and Route 53: WAF (Web Application Firewall) and Route 53 (DNS Service). WAF is associated with CloudFront to block common web attacks (such as SQL injection, XSS). Route 53 provides domain names for users.\nAmazon ElastiCache (Redis): In-memory data stores service. Helps maximize load reduction for RDS Database when there are repetitive queries (for example: retrieving the homepage product list). The .NET application will cache these \u0026ldquo;hot\u0026rdquo; data on ElastiCache, helping increase response speed. Similar to RDS, ElastiCache is also placed in a Private Subnet to ensure safety.\nNAT Gateway: Network Address Translation Service. NAT will provide secure Internet access for services in the Private Subnet (like Elastic Beanstalk). This allows servers to download security patches without being accessed directly from outside.\nAWS CodePipeline/CodeBuild: Continuous Integration and Deployment (CI/CD) services. These services are integrated with GitLab to automate the process: (1) CodeBuild builds .NET code, (2) CodePipeline deploys the new version to Elastic Beanstalk.\nData Flow\n[1]-[2] Users access the domain name (via Route 53) and are routed to CloudFront. Amazon WAF will filter this request.\n[3] (Static Flow) If it is a static file (image, css), CloudFront retrieves directly from Amazon S3.\n[4]-[6] (Dynamic Flow) If it is a dynamic request, CloudFront forwards via Internet Gateway to Application Load Balancer, then ALB sends the request to Elastic Beanstalk.\n[7]-[8] The .NET application (on Beanstalk) will check ElastiCache first, if not found, will query Amazon RDS.\n[9]-[10] When Elastic Beanstalk needs Internet access (to download patches), it will go through NAT Gateway then out to Internet Gateway.\n[11]-[14] (CI/CD Flow) When Dev pushes code to Github, CodePipeline and CodeBuild will automatically build and deploy the new version to Elastic Beanstalk.\n4. Technical Implementation Implementation Stages\nThe project will be divided into 4 main stages, lasting 12 weeks to ensure progress and quality:\nBuilding Technical Foundation: Focus on building the technical foundation, including finalizing the data model for main entities, setting up .NET 3-tier solution structure (Domain, Application, Persistence, WebShop), initializing repository on Github, and researching AWS services. (Weeks 1-4)\nBuilding Core Features: Complete Persistence Layer (Repositories, Unit of Work) and Application Layer (Services) for main tasks such as managing products, users, and orders. Simultaneously, WebShop Layer (Controllers, Views) will be built for login flows, shopping cart, payment, and start writing Unit Tests for Services. (Weeks 5-8)\nCloud Migration Preparation: Group refactors the source code for Cloud compatibility (migrating configurations to Environment Variables), drafts build scripts (buildspec.yml), and cleans up the project to prepare for the CI/CD process. (Weeks 9-11)\nFinalization and Deployment: Group provisions all resources on AWS (Elastic Beanstalk, RDS, ElastiCache, S3). Security and performance services (CloudFront, WAF) are configured, and the automated CI/CD pipeline is activated. Finally, UAT is performed, and system monitoring is established via CloudWatch. (Week 12)\nTechnical Requirements\nBackend: ASP.NET Core MVC 9.0. ORM: Entity Framework Core. Database: MS SQL Server 2022 (Local) and Amazon RDS for SQL Server (Cloud). Frontend: Bootstrap 5, jQuery, and Bootstrap Icons. Cloud Platform (AWS): Elastic Beanstalk, RDS, S3, CloudFront, WAF, Route 53, ElastiCache, VPC, NAT Gateway, CodePipeline, CodeBuild. Source Control: Git. Tools: Visual Studio 2022, Docker Desktop. Development Methodology\nApply Agile methodology (Scrum-like) to flexibly adjust according to requirements and ensure progress, adhering to the 4 proposed deployment stages. All work (features, bugs) will be tracked and managed via Kanban board, helping the group easily grasp the progress of each task (e.g., To Do, In Progress, Done). All new code must be reviewed via merge requests on Github before being merged into the main branch, ensuring consistent code quality.\nTesting Strategy\nTo ensure quality and stability, the group will perform 3 levels of testing. First is Unit Testing, focusing 100% on the Application Layer (e.g., ProductService, OrderService) by mocking repositories to isolate Business Logic, using standard .NET testing frameworks. The second level is Integration Testing, performed on the Staging environment (on Elastic Beanstalk) to check the interaction between the Application Layer and Persistence Layer (EF Core) with the real Amazon RDS Database. Finally, User Acceptance Testing will be performed on the Production environment for the group to check complete functional flows on the user interface such as \u0026ldquo;Register, Login, Payment\u0026rdquo;.\nDeployment Plan\nApply fully automated CI/CD process. The process is automatically triggered whenever Dev pushes code to Github. Github will send a webhook triggering AWS CodePipeline, this service will take the code and command AWS CodeBuild to compile the .NET project, run Unit Tests, and package the application into a .zip file. If CodeBuild succeeds, CodePipeline will take the .zip file and automatically deploy this new version to the Staging environment on Elastic Beanstalk.\n5. Roadmap \u0026amp; Milestones The project is planned to be executed in 12 weeks, divided into 4 main stages. This schedule ensures time for development, integration, and thorough testing.\nPhase 1 (Weeks 1 - 4): This stage focuses on building the technical foundation, including finalizing data models, setting up .NET 3-tier Solution Architecture, initializing Github Repository, and researching AWS services. The milestone of this stage is Solution Architecture and Repository established, along with AWS environment (VPC, Subnets).\nPhase 2 (Weeks 5 - 8): After Phase 1 is complete, the group will build core features, complete Persistence and Application Layers (Product Management, Orders) and basic feature flows on WebShop (Auth, Cart). The milestone is main feature flows (Login, View Product, Cart, Payment) operating stably locally, and Unit Tests for Services.\nPhase 3 (Weeks 9 - 11): This phase prepares for cloud migration. The group optimizes the source code (Refactoring), configures Environment Variables, drafts automation scripts (Buildspec), and cleans up the project for the CI/CD process.\nPhase 4 (Week 12): This final stage focuses on finalization and deployment, dependent on the stable Staging build from Phase 3. The group will configure security services (CloudFront, WAF, Route 53). The milestone is Version 1.0 successfully deployed to Production environment (Elastic Beanstalk), final User Acceptance Testing completed, and system monitored via CloudWatch.\n6. Budget Estimation Costs can be viewed on AWS Pricing Calculator\nOr download budget estimation file.\nInfrastructure Costs\nEstimates from AWS Pricing Calculator show the monthly operating cost of this architecture is 138.06 USD, with an upfront cost of 0.00 USD. The group\u0026rsquo;s cost optimization strategy focuses on maximizing AWS Free Tier usage and managed services. The figure of 138.06 USD/month is a realistic cost for long-term operation (after 12 months) of a complete, scalable, and highly secure e-commerce system.\nCosts for Elastic Beanstalk are broken down into the resources it manages: Amazon EC2 (1 instance t3a.small) costing 19.15 USD/month and Elastic Load Balancing (1 Application Load Balancer) costing 18.69 USD/month. Amazon VPC service costs 46.02 USD/month, this is the cost for 1 NAT Gateway, a mandatory component for Elastic Beanstalk\u0026rsquo;s Private Subnet security design. Regarding database and cache, Amazon RDS for SQL Server (Express Edition version on db.t3.micro) costs 25.86 USD/month, and Amazon ElastiCache (cache.t4g.micro) is 17.52 USD/month. Security and CI/CD services like WAF (7.20 USD/month), CloudFront (2.43 USD/month), Route 53 (0.90 USD/month), S3 (0.17 USD/month), and CodeBuild (0.12 USD/month) make up the remaining costs.\nThe most important cost optimization strategy is leveraging AWS Free Tier in the first 12 months. Although the total estimate is 138.06 USD/month, many core services herein (including EC2 t3a.small, RDS db.t3.micro, ElastiCache t4g.micro, S3, and CloudFront) are within the Free tier free for 12 months. Therefore, the actual operating cost in the first year will be significantly lower, mainly consisting of costs for NAT Gateway (46.02 USD) and WAF (7.20 USD).\nRegarding ROI calculation, and initial investment is nearly zero (as infrastructure costs are covered within Free Tier and development costs are the group\u0026rsquo;s effort during the internship). Profit is almost immediate, as the solution directly solves revenue loss problems (from manual inventory management) and missed market opportunities (due to offline-only sales) stated in the Problem Statement (Part 1). Therefore, ROI (return on investment) is very high.\n7. Risk Assessment Some potential risks lie in three areas: Technical, Business, and Operational. Thus a mitigation plan and contingency plan have been prepared for high-impact risks.\nTechnical: System Overload (Performance Bottleneck):\nImpact: High | Probability: Medium This is the risk of the system being slow or crashing when there is high traffic volume. The group\u0026rsquo;s mitigation strategy is to use ElastiCache to offload queries for RDS, configure Auto Scaling (in Elastic Beanstalk) with reasonable triggers (e.g., CPU \u0026gt; 70%), and use CloudFront to cache static files. The contingency plan is to use CloudWatch Alarms for immediate alerts, and if RDS overloads, the group will perform vertical scaling of the RDS instance immediately. Business: Low User Adoption:\nImpact: High | Probability: Medium This is the risk that mini-market owners find the solution too complex and do not use it. To mitigate this risk, the group will stick to a simple frontend design (Bootstrap), gather shop owner feedback early from Phase 2, and provide instruction manuals. The contingency plan is if adoption is low after deployment, the group will perform an additional Sprint (Phase 5) to prioritize adjusting features based on gathered feedback. Operational: Data Loss / Breach:\nImpact: Critical | Probability: Low The group\u0026rsquo;s mitigation strategy is to configure RDS for automatic daily backups, place RDS and Beanstalk in Private Subnet, use WAF to block attacks, and manage connection strings via Beanstalk environment variables. The contingency plan is if data is lost, the group will perform Point-in-Time Recovery (PITR) immediately from RDS backup. 8. Expected Outcomes The goal of this solution is to directly address the problems stated in the Problem Statement section. Regarding business metrics, the group expects to reduce inventory management errors by 90% (compared to Excel/notebooks), reduce checkout time at the counter by 50%, and achieve at least 20% new revenue from online channels in the first 6 months. Regarding technical metrics, the goal is to maintain 99.9% uptime, ensure average page load time under 2 seconds (thanks to CloudFront and ElastiCache), and stable deployment frequency via CI/CD pipeline.\nBenefits are expected to increase over time. In the short-term (0-6 months), mini-market owners will see immediately improved user experience and significantly improved operations (automated inventory management). In the medium-term (6-18 months), value comes from market expansion (reaching online customers) and starting to collect valuable business data. Long-term value and strategic capabilities gained are the ability to make data-driven decisions (e.g., knowing which products sell well) and easy system scalability (adding more new stores) thanks to Solution Architecture on Elastic Beanstalk and RDS.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.6-cicd/5.6.2-codepipeline/","title":"Set up CodePipeline","tags":[],"description":"","content":" Access CodePipeline \u0026gt; Create pipeline\nCategory: Select Build custom pipeline\nSettings: Select New service role\nSource Stage: Select GitHub (via GitHub App) \u0026gt; Connect to GitHub \u0026gt; Select Repo and branch that you deploy to cloud\nBuild Stage: Select AWS CodeBuild \u0026gt; Select project MiniMarket-Build just created\nTest Stage: Click Skip test stage\nDeploy Stage:\nProvider: AWS Elastic Beanstalk Application name: MiniMarket-App Environment name: Select running environment Click Create pipeline\nIf Deploy step has Permission error, go to IAM Role of CodePipeline and grant permission AdministratorAccess-AWSElasticBeanstalk\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.7-security/5.7.2-waf/","title":"Set up Firewall (WAF)","tags":[],"description":"","content":" Access WAF \u0026amp; Shield \u0026gt; Protection packs (webs ACLs) \u0026gt; Create protection pack (web ACL) App category: E-commerce \u0026amp; transaction platforms App focus: Both API and web Add resources \u0026gt; Add CloudFront or Amplify resources \u0026gt; Select CloudFront distribution created in previous section Choose initial protections \u0026gt; Build your own pack from all of the protections AWS WAF offers \u0026gt; AWS-managed rule group:\nAdd Core rule set (Block bot, bad IP) Add SQL database (Block SQL Injection) Testing: Access URL: https://[domain]/?id=1 OR 1=1. If receiving error 403 Forbidden, WAF is active.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Explore AWS credit system and cost management practices. Deepen understanding of EC2, VPC, and S3 services. Reinforce cloud networking concepts through hands-on labs and tutorials. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 1-2 - Completed 5 missions to receive $100 AWS credit - Learned about charges incurred after using AWS services and how to clean up resources 09/22/2025 09/23/2025 https://github.com/vanhoangkha/AWS-Free-Tier 2 - Installed Virtual Machine and Linux OS - Watched videos and completed labs from Module 2 09/23/2025 09/23/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i 3 - Studied theory and watched content from Module 3 \u0026amp; 4 and related labs 09/24/2025 09/24/2025 https://www.youtube.com/watch?v=AQlsd0nWdZk\u0026list=PLahN4TLWtox2a3vElknwzU_urND8hLn1i 4 - Completed lab: Getting Started with Amazon VPC and AWS Site-to-Site VPN - Used ChatGPT to summarize AWS-related terms encountered during labs 09/25/2025 09/25/2025 https://000003.awsstudygroup.com/vi/ Week 3 Achievements: Successfully received $100 AWS Free Tier credit. Strengthened understanding of EC2 and S3 storage services. Gained deeper insight into VPC networking and VPN configuration. Memorized and clearly understood various AWS terms and concepts during hands-on practice. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.5-app/5.5.3-app-config/","title":"Configure Environment Variables","tags":[],"description":"","content":"To enable the application to connect to Database and Redis, we do not hardcode in the code but use Environment Variables\nGo to Beanstalk Environment \u0026gt; Configuration \u0026gt; Updates, monitoring, and logging \u0026gt; Edit\nScroll down to Environment properties section\nAdd the following variables:\nName: ConnectionStrings__DefaultConnection\nValue: Server=sql-shop-db\u0026hellip;.rds.amazonaws.com;Database=MiniMarketDB;User Id=admin;Password=PASSWORD YOU SET;TrustServerCertificate=True; Name: ConnectionStrings__RedisConnection\nValue: webapp.redis.cache\u0026hellip;:6379 Name: VnPay__IPNUrl\nValue: https://[cloudfrontdomain].cloudfront.net/Payment/VnPayIPN Name: VnPay__ReturnUrl\nValue: https://[cloudfrontdomain].cloudfront.net/Payment/VnPayReturn Click Apply. Server will restart to apply new configuration "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"“Reinventing DevSecOps” Report Event Purpose Redefine the secure software development process (DevSecOps Lifecycle) from planning to operations. Introduce a comprehensive toolchain to integrate security into every stage of CI/CD. Build a \u0026ldquo;Security-First\u0026rdquo; mindset for development and operations teams. Organizer CMC Global Highlights 1. The DevSecOps Lifecycle The process is divided into 7 closed stages, ensuring security is not a \u0026ldquo;bottleneck\u0026rdquo; but part of the flow:\nPLAN: Identify security requirements \u0026amp; risks right from the start. Align goals between Dev, Sec, and Ops. Create a security roadmap aligned with project goals. CODE: Apply clean code and secure coding standards. Use SAST (Static Application Security Testing) directly in the IDE to detect errors early. Form a \u0026ldquo;Security-first\u0026rdquo; mindset for developers. BUILD: Automate security checks in the CI/CD Pipeline. Perform dependency and binary scans. Ensure secure and consistent builds (Immutable Artifacts). TEST: Run vulnerability scans and DAST (Dynamic Application Security Testing). Perform Penetration Testing. DEPLOY: Check configuration and IaC (Infrastructure as Code) before deployment. Monitor runtime configuration. OPERATE: Automate patching and continuous security updates. Have an incident response process. MONITOR: Continuously monitor for threats. Use Real-time Analytics and alerting tools. 2. DevSecOps Toolchain Overview A robust DevSecOps system requires the coordination of many specialized tools:\nPre-commit \u0026amp; Code Quality: SonarQube, Codacy: Check code quality. GitLeaks: Scan and prevent leaking Secrets/Keys in code before commit. Dependency \u0026amp; SBOM Scanning: Syft, Grype, Dependency-Track: Manage software packages and detect vulnerabilities in 3rd party libraries. IaC \u0026amp; Policy-as-Code: Checkov, Tfsec: Scan for security errors in Terraform/Kubernetes files. OPA Gatekeeper, Kyverno: Enforce compliance policies automatically on Clusters. SAST / DAST \u0026amp; Security Tests: Trivy, Checkmarx: Detect comprehensive vulnerabilities from Code to Runtime. CI/CD Integration: Jenkins, GitHub Actions, GitLab CI, ArgoCD: Platforms to automate the entire process above. Monitoring \u0026amp; Logging: Prometheus, Grafana, Loki: Monitor system health (Observability). Alerting \u0026amp; Governance: Slack, Email, AI Anomaly Detection: Instant alerts when issues occur. What I Learned \u0026ldquo;Shift Left\u0026rdquo; Mindset Security should not be left to the end (Test/Operate stage) but must be shifted left - meaning done right from the Plan and Code stages. Detecting errors early saves repair costs significantly. The Importance of Automation Security cannot be done manually in the Cloud era. Scanning tools need to be integrated into the Pipeline to block faulty builds automatically. Supply Chain Security Risk Management By scanning Dependencies (SBOM), we can prevent attacks on 3rd party libraries (similar to the Log4j incident). Application to Work Integrate GitLeaks: Install pre-commit hook immediately to prevent accidentally pushing AWS Access Keys to GitHub. Deploy SonarQube: Integrate into current CI process to measure technical debt and security vulnerabilities. Apply IaC Scanning: Use Checkov to scan CloudFormation/Terraform files before applying infrastructure to AWS. Monitoring: Set up Grafana Dashboard to monitor real-time application status. Event Experience Although only participating by following the materials, the content from CMC Global provided a very systematic view of DevSecOps.\nClarity in process The slide on DevSecOps Lifecycle helped me visualize the big picture clearly, knowing what needs to be done at each stage instead of just focusing on coding as before. Practical Toolchain The Toolchain slide is a real \u0026ldquo;treasure\u0026rdquo;. It provides a list of Industry Standard tools that I can research and apply immediately to my MiniMarket project (for example, using Trivy to scan Docker Images).\nThe event emphasized that: In the AI and Cloud era, Security is not a feature, but a culture that needs to be built from the very first lines of code.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.4-data/5.4.3-elasticache/","title":"Initialize ElastiCache Redis","tags":[],"description":"","content":" Access ElastiCache \u0026gt; Subnet groups \u0026gt; Create subnet group Name: redis-private-group Subnets: Select 2 Private Subnets Go to Redis OSS caches \u0026gt; Create cache At Cluster settings screen: Engine: Select Redis OSS Deployment option: Select Node-based cluster Creation method: Select Cluster cache (Configure and create a new cluster) Cluster mode: Select Disabled (Simple mode, 1 Shard) At Location screen:\nLocation: AWS Cloud Multi-AZ: Uncheck (Enable) Note: Disable this feature to save costs for Lab environment Auto-failover: Uncheck (Enable) At Cache settings screen:\nEngine version: Leave default (Ex: 7.1) Port: 6379 Node type: Select t3 family \u0026gt; Select cache.t3.micro Number of replicas: Enter 0 (We only need 1 primary node, no replica node needed) At Connectivity screen: Network type: IPv4 Subnet groups: Select Choose existing subnet group \u0026gt; Select redis-private-group just created At Advanced settings screen (Important): Encryption at rest: Enable (Default) Encryption in transit: Uncheck (Disable) Reason: Disabling encryption in transit simplifies connection from .NET code in internal VPC environment without configuring complex SSL certificates Selected security groups: Select Manage \u0026gt; select sg-redis-cache (Uncheck default) Scroll to the bottom and click Create 3. Get connection information Initialization process will take about 5-10 minutes\nWhen status changes to Available (Green) Click on Cluster name (webapp or name you set) At Overview tab, find Primary endpoint Copy this connection string (Ex: webapp.xxxx.cache.amazonaws.com) This Endpoint will be used to configure ConnectionStrings__RedisConnection environment variable for Elastic Beanstalk in the following steps.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.3-network/","title":"Network Infrastructure Setup","tags":[],"description":"","content":"Overview In this section, we will build the network foundation for the MiniMarket application. A secure network architecture is a prerequisite to protect the application and data\nWe will design a VPC consisting of:\nPublic Subnet: Dedicated to components communicating directly with the Internet (Load Balancer, NAT Gateway). Private Subnet Dedicated to components requiring security (App Server, Database, Redis) Additionally, we will configure NAT Gateway to allow servers inside the Private Subnet to download updates and Docker Images from the Internet without exposing IP addresses externally\nContent Create VPC \u0026amp; Subnet Configure Internet \u0026amp; NAT Gateway Configure Route Table "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Blog 1 - Unlocking the Power of AI in Manufacturing with PTC Kepware+ on AWS This blog mention to the future of manufacturing and industrial products depends on connectivity, intelligence, and operations. By applying Kepware+ best practices with AWS, businesses will unlock the full value of industrial data, transforming operational barriers into growth opportunities. Whether your goal is predictive maintenance, energy optimization, regulatory compliance, or supply chain resilience, the Kepware and AWS partnership delivers a proven, secure, and scalable roadmap for transforming the new business.\nBlog 2 - Building Resilient Healthcare Systems Through Cloud Computing This blog introduces to the resilience of clinical and operational healthcare systems is not just a technical matter but also an important policy priority. Even short-term disruptions to electronic health records or clinical systems can directly affect patient care and safety.\nBlog 3 - Building a Just-in-Time Knowledge Base with Amazon Bedrock This blog introduces how to Multi-tenant SaaS systems often need to process a large volume of documents, but traditional RAG approaches consume excessive resources because they ingest and store embeddings for documents that may never be queried.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Learn and practice Serverless Automation using AWS Lambda to optimize EC2 operation costs. Implement Advanced Monitoring with Amazon CloudWatch and Grafana for system observability. Explore CloudWatch Metrics, Logs, Alarms, and Dashboards for real-time analytics. Learn to manage and control access through IAM Policies and Resource Tags. Understand how to use AWS Systems Manager for patching, remote commands, and centralized administration. Implement Infrastructure as Code (IaC) using CloudFormation and AWS CDK. Practice building advanced, multi-service architectures and nested stacks with AWS CDK Advanced. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Serverless Automation with AWS Lambda + Automate EC2 instance scheduling using Lambda functions. + Configure IAM Role and tags for automation. + Test and validate automatic start/stop of EC2 instances. - Advanced Monitoring with CloudWatch and Grafana + Install Grafana on EC2 instance. + Connect Grafana to CloudWatch. + Create dashboards and configure alerting rules. 30/09/2025 30/09/2025 https://000022.awsstudygroup.com/ https://000029.awsstudygroup.com/ 3 - CloudWatch Advanced Workshop + Explore CloudWatch Metrics, Logs, Alarms, and Dashboards. + Use Container Insights for ECS, EKS, and Fargate monitoring. - Resource Organization with Tags and Resource Groups + Create and manage resource tags across EC2, S3, and IAM. + Build tag-based Resource Groups for centralized management. 01/10/2025 01/10/2025 https://000036.awsstudygroup.com/ https://000027.awsstudygroup.com/ 4 - Access Control with IAM and Resource Tags + Define IAM policies with tag-based conditions for least privilege. + Create IAM roles for EC2 administrators with conditional access. + Test permissions to verify tag-based access control. - Systems Management with AWS Systems Manager + Configure Patch Manager to automate OS updates. + Use Run Command to execute tasks on multiple EC2 instances. + Review compliance and clean up resources. 02/10/2025 02/10/2025 https://000028.awsstudygroup.com/ https://000031.awsstudygroup.com/ 5 - Infrastructure as Code with AWS CloudFormation + Create CloudFormation templates to deploy AWS infrastructure. + Manage resources through CloudFormation Stacks. - Cloud Development Kit (AWS CDK) Essentials + Write CDK templates using programming languages. + Deploy and update resources through CDK. 03/10/2025 03/10/2025 https://000037.awsstudygroup.com/ https://000038.awsstudygroup.com/ 6 - AWS CDK Advanced Workshop + Build a multi-service architecture using API Gateway, ECS, ALB, Lambda, and S3. + Create nested stacks for modular deployment. - Infrastructure as Code Workshop Series + Learn IaC concepts, frameworks, and benefits. + Practice deploying multi-tier architectures with CloudFormation and CDK. 04/10/2025 04/10/2025 https://000076.awsstudygroup.com/ https://000102.awsstudygroup.com/ Week 4 Achievements Day 2 – Serverless Automation \u0026amp; Advanced Monitoring Implemented AWS Lambda to automate EC2 instance lifecycle management using scheduled events and tags. Configured IAM Roles and verified automation functionality for starting and stopping instances. Learned to apply Savings Plans for continuous workload cost optimization. Installed Grafana on EC2 and integrated it with CloudWatch for real-time metrics visualization. Built dashboards showing CPU, memory, and network utilization. Configured alerting rules to detect threshold breaches and improve incident response time. Day 3 – CloudWatch Advanced Workshop \u0026amp; Resource Organization Gained in-depth understanding of Amazon CloudWatch for proactive system monitoring. Configured Metrics, Logs, Alarms, and Dashboards for application and infrastructure visibility. Used Container Insights to monitor ECS and EKS workloads. Built CloudWatch Dashboards summarizing key performance indicators. Applied resource tagging to classify AWS resources by owner, purpose, and environment. Created Resource Groups for centralized management and automated operations across tagged assets. Improved monitoring efficiency and governance in multi-resource environments. Day 4 – Access Control \u0026amp; Systems Management Implemented IAM tag-based policies to enforce least privilege and secure EC2 access. Created custom IAM Roles with conditional tag-based permissions for administrators. Verified access control behavior through testing and enforced tag compliance. Learned AWS Systems Manager (SSM) for centralized automation and patch management. Configured Patch Manager for automatic OS and security updates. Used Run Command to manage multiple instances simultaneously. Strengthened security posture and operational consistency through automation. Day 5 – Infrastructure as Code with CloudFormation \u0026amp; AWS CDK Practiced deploying infrastructure automatically using CloudFormation templates in YAML. Created and managed CloudFormation Stacks to provision VPCs, subnets, and EC2 instances. Learned rollback and stack update mechanisms for safer deployments. Implemented AWS CDK to define infrastructure using Python/TypeScript code instead of raw YAML. Deployed, modified, and updated resources through CDK Stacks. Gained experience in Infrastructure as Code (IaC) and DevOps automation workflows. Day 6 – AWS CDK Advanced \u0026amp; Infrastructure as Code Workshop Designed and deployed multi-service architectures using AWS CDK v2.151.0, integrating API Gateway, ALB, ECS (Fargate), Lambda, and S3. Implemented nested stacks to modularize deployments for scalability and maintainability. Learned to orchestrate complex infrastructure across services via reusable CDK constructs. Reviewed key IaC principles and compared frameworks such as CloudFormation, SAM, CDK, and Terraform. Deployed a three-tier web application and automated infrastructure creation through code. Integrated IaC principles into DevOps pipelines for version-controlled, repeatable, and secure deployments. Strengthened proficiency in infrastructure automation, scalability, and governance. Summary Automated EC2 scheduling and cost optimization with AWS Lambda. Enhanced monitoring through CloudWatch, Grafana, and Container Insights. Secured infrastructure access with IAM tag-based policies. Centralized management and patching via AWS Systems Manager. Implemented Infrastructure as Code (IaC) using CloudFormation and AWS CDK. Built advanced, multi-service architectures using CDK Advanced and nested stacks. Strengthened overall understanding of DevOps automation, cloud governance, and scalable infrastructure design on AWS. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.4-data/","title":"Data Layer Deployment","tags":[],"description":"","content":"Overview Data is the most important asset of every system. Therefore we will set up the data layer (Data Layer) for MiniMarket with criteria: Maximum Security and High Performance\nWe will deploy two core services:\nAmazon RDS (Relational Database Service): Use SQL Server to store business data (Products, Orders, Users). Database will be placed in Private Subnet to prevent direct access from the Internet Amazon ElastiCache (Redis): Use Redis as cache memory (In-memory Cache) to store Login Sessions and offload queries for the main Database Content Set up Security Groups for DB \u0026amp; Cache Initialize Amazon RDS (SQL Server) Initialize Amazon ElastiCache (Redis) "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"“AI/ML/GenAI on AWS” Report Event Purpose Provide an overview of Foundation Models and the Amazon Bedrock platform Guide on Prompt Engineering techniques from basic to advanced Explain the architecture and operational workflow of RAG (Retrieval Augmented Generation) Introduce AWS\u0026rsquo;s ecosystem of Pretrained AI services and Frameworks for building AI Agents Speaker List Lam Tuan Kiet Danh Hoanh Hieu Nghi Dinh Le Hoang Anh Highlights Foundation Models \u0026amp; Amazon Bedrock Foundation Models (FMs): Trained using self-supervised training, capable of processing many tasks. Amazon Bedrock: Platform providing access to leading models like Luma, Deepseek\u0026hellip; Prompt Engineering (AI Command Techniques) Basic process: Prompt → Bedrock → Response. Key techniques:\nZero-Shot Prompting: Asking questions directly without providing sample data. Few-Shot Prompting: Providing a few examples (example frame) for the model to learn the answer structure when encountering similar questions. Chain of Thought (CoT): Guiding AI on step-by-step reasoning, helping AI provide more accurate answers based on learned logic. Retrieval Augmented Generation (RAG) Currently popular model (used widely in Banking). Process includes: Retrieval → Augmentation → Generation.\nEmbeddings: Convert human language into Vectors. Using Amazon Titan Embedding (supports multiple languages). RAG in Action: Data preparation: Data source → Document chunk → Embeddings model → Vector store. Query processing: User input → Embeddings model → Vector → Semantic search (in Vector store) → Context → Prompt augmentation → LLM → Response. Other Pretrained AI Services AWS provides specialized services with optimal costs:\nAmazon Rekognition (Computer Vision): Image/video analysis, face and object detection. Pricing: ~$0.0013/image. Amazon Translate: Real-time or batch text translation. Pricing: ~$15/million characters. Amazon Textract: Extract text and layout from documents (OCR). Pricing: ~$0.05/page. Amazon Transcribe: Convert speech to text, supports streaming. Amazon Polly: Convert text to speech, supports Real-time TTS. Pricing: ~$4/million characters. Amazon Comprehend (NLP): Sentiment Analysis, key phrase extraction, PII detection. Pricing: ~$0.0001/100 chars. Amazon Kendra: Intelligent Search service, supports Natural Language Search and RAG. Amazon Lookout Family: Detect anomalies in Metrics, Equipment, and Vision. Amazon Personalize: Personalized recommendation system for users. AI Agents \u0026amp; Frameworks Pipecat: Framework for voice/multimodal AI agents, optimized for real-time conversation assistants. Amazon Bedrock AgentCore: Supported frameworks: Langgraph, Langchain, Strands Agents SDK. Process from Idea → Production needs to focus on: Performance, Scalability, Security, Governance. Core components: Runtime, Memory, Identity, Gateway, Code Interpreter, Browser tool, Observability. What I Learned Prompting Mindset Optimization Techniques: Clearly understand the differences between Zero-shot, Few-shot, and Chain of Thought to apply to specific problem complexities. Structuring: Providing examples helps better control the model\u0026rsquo;s output format. RAG Architecture Vector Database: Understand the critical role of Vector Store and Semantic Search in providing accurate context for LLMs. Embedding Models: The importance of choosing embedding models (like Amazon Titan) to support multiple languages and search accuracy. Service Selection (Trade-offs) Cost vs Flexibility: Know how to balance costs between using Pretrained Services (pay per request/char) versus building custom models or using general LLMs. Use case specific: Each service (Rekognition, Textract\u0026hellip;) solves a specific problem better and cheaper than forcing an LLM to do everything. Application to Work Deploy RAG: Apply Retrieval Augmented Generation model to build internal search systems for enterprise/banking. Integrate Pretrained Services: Use Amazon Textract and Comprehend to automate document and record processing. Build intelligent Chatbots: Combine Amazon Lex/Bedrock with Pipecat framework to create real-time conversational virtual assistants. Cost Optimization: Use Caching for Amazon Polly or select the right tier of AI services to minimize operating costs. Event Experience Participating in the “Generative AI with Amazon Bedrock” event helped me systematize knowledge about GenAI and the AWS ecosystem. Some highlights:\nPractical Knowledge from Experts Speakers shared real-world experiences on applying RAG and Prompt Engineering. Deeper understanding of the AI reasoning process through Chain of Thought. Overview of AI Services Not stopping at LLMs, the event provided a broad view of Specialized AI Services like Lookout, Kendra, Personalize\u0026hellip; helping solve niche problems effectively. The Pricing analysis gave me more data to make decisions when designing solutions. Tech Trend Updates Introduced to Agentic AI and components of Bedrock AgentCore, opening new directions in building AI applications capable of executing complex tasks (Idea to Production).\nApproached Pipecat framework, an optimal solution for voice AI agents.\nIn conclusion, the event provided a solid knowledge foundation about Amazon Bedrock and GenAI techniques, thereby helping me feel more confident in proposing and implementing AI solutions for projects.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Translate the blog of AWS Buid the database of project Setup enviroment on computer Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Take on blog translation assignments from AWS\u0026rsquo;s Mentor - Read and take notes on the assignment 06/10/2025 06/10/2025 3 - Meet with the team to brainstorm project ideas 07/10/2025 07/10/2025 4 - Set up enviroments for coder 07/10/2025 08/10/2025 6 - Buid the database of project 09/10/2025 11/10/2025 Week 5 Achievements: Successfully completed the translation of AWS blog assignments, including taking detailed notes and gaining a solid understanding of the related concepts.\nParticipated in a team meeting to brainstorm and discuss project ideas, helping to establish a clear development direction.\nFully set up the development environment on the computer to ensure smooth project execution and alignment with the team’s configuration.\nBuilt the project’s database structure, including drafting the ERD, creating tables, defining primary and foreign keys, and establishing relationships between entities while ensuring consistency and optimization.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.5-app/","title":"Application Deployment","tags":[],"description":"","content":"Overview After having network and data infrastructure, the next step is to bring .NET Core application source code to Cloud. Instead of managing each EC2 virtual server manually, we will use the Platform-as-a-Service (PaaS) platform which is AWS Elastic Beanstalk\nGoals of this module:\nContainerization: Package MiniMarket application into Docker Container to ensure uniform running environment (Dev = Prod) Deployment: Deploy Container to Elastic Beanstalk. The system will automatically provision EC2, configure Load Balancer and Auto Scaling Group Connectivity: Configure so application connects securely to RDS and Redis via Environment Variables Content Package application with Docker Initialize Elastic Beanstalk Environment Configure Database \u0026amp; Redis connection "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"“DevOps on AWS” Report Event Purpose Guide career paths in DevOps and Cloud fields. Deeply understand CI/CD processes and Containerization. Analyze the role of Infrastructure as Code (IaC) versus ClickOps. Compare Orchestration solutions on AWS (ECS vs EKS) and Monitoring/Observability strategies. Highlights Next-Generation DevOps Roadmap Related roles: DevOps Engineer, Cloud Engineer, Platform Engineer, Site Reliability Engineer (SRE). T-shaped Skill: A skill development model with broad knowledge across many areas and deep knowledge in one specific area. Advice for beginners: Do: Start with Fundamentals, learn through Real Projects, Document everything, focus on mastering one skill at a time. Don\u0026rsquo;t: Get stuck in \u0026ldquo;Tutorial Hell\u0026rdquo;, copy-paste blindly, compare yourself to others, give up after failures. Continuous Integration \u0026amp; Deployment (CI/CD) CI (Continuous Integration): The process of frequently integrating code into a shared repository. Distinguishing CD: Continuous Delivery: Automated up to Acceptance Test; deployment to Production requires a manual trigger. Continuous Deployment: Fully automated from code to Production. Infrastructure as Code (IaC) Problems with ClickOps: Slow, prone to Human Error, inconsistent, difficult to collaborate. Benefits of IaC: Automation, Scalability, Reproducibility, enhanced collaboration. AWS CloudFormation: AWS\u0026rsquo;s built-in IaC tool using JSON/YAML templates. Stack: A collection of resources managed together. Drift Detection: Detects discrepancies between actual configuration and the template (when someone manually modifies resources). AWS CDK (Cloud Development Kit): Uses programming languages (Python, TS\u0026hellip;) to define infrastructure. Concepts: L1 (Mapping 1:1), L2, L3 Constructs. CLI commands: cdk init, cdk synth, cdk deploy, cdk diff, cdk destroy. Terraform: Open-source tool, supports Multi-cloud, uses HCL language, manages state via State file. Container Ecosystem Docker Fundamentals: Dockerfile (build definition) → Image (packaging blueprint) → Container (runtime). Amazon ECR: AWS\u0026rsquo;s private container registry, supporting image scanning, immutable tags and lifecycle policies. Container Orchestration: Manages container lifecycle (restart, scale, distribute traffic). Amazon ECS: AWS native solution. Supports Launch types: EC2 (server management) and Fargate (Serverless - easier). Amazon EKS: Managed Kubernetes service. Suitable for complex systems requiring K8s experience. Amazon App Runner: Simplest solution to deploy web apps/APIs quickly and cost-effectively. Monitoring \u0026amp; Observability Distinction: Monitoring: Tracking Logs, Metrics (How is the system performing?). Observability: Deeply understanding root causes (Why is the system performing this way?). Amazon CloudWatch: Collects Metrics (CPU, RAM, Network\u0026hellip;) and Logs in real-time. Alarms: Alerts and automated responses. Dashboards: Visualize operational data. AWS X-Ray: Distributed tracing for microservices, helping visualize service maps and analyze performance bottlenecks. What I Learned System Thinking Infrastructure Drift: Understanding the risks of manual resource modification outside of IaC and the importance of using Drift Detection. Trade-offs: Knowing how to select IaC tools (CDK for AWS-centric, Terraform for Multi-cloud) and Orchestration tools (ECS for beginners/simple needs, EKS for advanced features). Operational Skills Standard Process: The core difference between Continuous Delivery and Continuous Deployment lies in the manual approval step to Production. Container Management: Understanding the workflow from Dockerfile to ECR and how ECS/EKS orchestrates container operations. Application to Work Transition to IaC: Start writing CloudFormation or CDK for current projects instead of operating on the Console. Optimize Pipeline: Review CI/CD processes, integrate automated testing steps before deployment. Implement Observability: Integrate AWS X-Ray into applications to trace requests across microservices, combined with CloudWatch Alarms for proactive monitoring. Refactor Docker: Optimize Dockerfiles and use ECR Lifecycle Policies to manage image storage space. Event Experience Participating in the “Next-Generation DevOps \u0026amp; Cloud Architecture” event was a crucial stepping stone helping me clearly define my DevOps skill development path.\nClear Orientation The speaker outlined a very practical learning Roadmap with the advice \u0026ldquo;Don\u0026rsquo;t stay in Tutorial Hell\u0026rdquo; - which resonated with me. The T-shaped skill model helped me realize I don\u0026rsquo;t need to know everything at once but should focus deeply on one area first. In-depth Tool Knowledge The detailed comparison between ECS and EKS made me more confident in choosing the right compute solution for my project (as a beginner, ECS Fargate is the optimal choice). The presentation on IaC and Drift Detection completely changed my mindset on infrastructure management: \u0026ldquo;Use code, not clicks\u0026rdquo;. The Importance of Observability I realized that Monitoring (looking at charts) is not enough; achieving Observability (understanding the nature) through tools like AWS X-Ray is necessary to thoroughly resolve issues in distributed systems. Some photos from the event Add your photos here This event not only provided technical knowledge but also inspired a professional mindset, from building CI/CD culture to automating everything possible.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Deploying Cloud-Native MiniMarket Application on AWS Overview This workshop provides a comprehensive guide on re-platforming the MiniMarket e-commerce application (developed on the .NET Core platform) from a local environment to the AWS cloud infrastructure using a Cloud Native architecture.\nWe will not merely rent a virtual server (EC2) to run code. Instead, we will build a distributed system that is highly scalable, secure, and automated based on managed services.\nWe will establish a Multi-tier architecture consisting of core components:\nCompute: Use AWS Elastic Beanstalk combined with Docker to simplify application deployment and management, supporting automatic Auto Scaling based on traffic. Data \u0026amp; Caching: Migrate from local SQL Server to Amazon RDS (placed in Private Subnet) to ensure data security. Simultaneously, deploy Amazon ElastiCache (Redis) to manage User Sessions, ensuring high performance for the application. Networking \u0026amp; Security: Use VPC along with Public/Private Subnet and NAT Gateway for secure outbound connection, and protect the application against attacks using AWS WAF combined with CloudFront. DevOps: Build a CI/CD process using AWS CodePipeline and CodeBuild, allowing automation of the process from committing code to GitHub until the application runs in the Production environment Content Workshop Overview Prerequisites Network Infrastructure Setup (VPC, NAT, Security Groups) Data Layer Deployment (RDS \u0026amp; Redis) Application Deployment with Elastic Beanstalk \u0026amp; Docker Automation with CI/CD Pipeline Optimization and Security(S3, CloudFront, WAF) Monitoring (CloudWatch) Resource Cleanup "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Begin setting up the MVC structure for the project. Implement basic routing and controller handling. Create base models following the designed database structure. Prepare initial views and layout templates. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Initialize project structure following MVC architecture - Configure routing for main modules 13/10/2025 13/10/2025 3 - Create base Models according to the database (Entities + Relationships) 14/10/2025 14/10/2025 Database Schema / ERD 4 - Build initial Controllers (HomeController, AuthController, DashboardController) 15/10/2025 16/10/2025 5 - Create Views folder structure - Implement layout templates (header, footer, navigation) 16/10/2025 17/10/2025 Bootstrap / MVC Docs Week 6 Achievements: Successfully initialized the project using the MVC architectural pattern, ensuring clear separation of concerns. Configured routing for core modules, enabling stable navigation between pages. Created foundational Models based on the project’s database schema, helping align backend logic with the data layer. Built essential Controllers to handle main actions and business logic. Designed and organized the View layer, including shared layouts (header, footer), improving consistency and future scalability. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.6-cicd/","title":"CI/CD Automation","tags":[],"description":"","content":"Overview In the Cloud Native environment, manual deployment (Manual Deployment) is risky and time-consuming. This module will guide you to build a fully automated CI/CD (Continuous Integration / Continuous Deployment) process\nThe process operates as follows:\nSource: Developer pushes code (Push) to GitHub Build: AWS CodePipeline detects changes and activates AWS CodeBuild. CodeBuild will package the Docker Image and push to the Amazon ECR repository Deploy: Pipeline automatically commands Elastic Beanstalk to update the latest version from ECR without service interruption Content Create Build Project with AWS CodeBuild Set up AWS CodePipeline "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/4-eventparticipated/4.6-event6/","title":"Event 6","tags":[],"description":"","content":"“AWS Security Governance \u0026amp; Automation” Report Event Purpose Introduce the vision of Cloud Club and the importance of community. Share methods for centralized Identity Management and account security. Guide on Multi-Layer Security Visibility strategy. Automate security incident response process (Automated Alerting) with EventBridge. Highlights Identity \u0026amp; Access Management (IAM \u0026amp; Governance) Single Sign-On (SSO): \u0026ldquo;One login, multiple systems\u0026rdquo; mechanism. Instead of creating many scattered IAM Users, SSO allows centralized identity management, helping users log in once to access multiple AWS accounts/applications. Service Control Policies (SCPs): A type of Organizational Policy used to set up \u0026ldquo;guardrails\u0026rdquo;. SCPs limit maximum permissions for member accounts in AWS Organization. Credentials Spectrum: Long-term: IAM User Access Keys (do not expire) → High risk, need to limit usage. Short-term: IAM Roles, STS tokens (expire after 15 minutes - 36 hours) → Higher security, is best practice. MFA (Multi-Factor Authentication): Mandatory security layer for every account. Multi-Layer Security Visibility IAM Access Analyzer: Tool helping detect resources (S3, KMS, IAM Roles\u0026hellip;) being publicly shared or shared with untrusted accounts. Event Classification (Logging): Management Events: Who did what to resources? (Ex: Create EC2, Delete S3 Bucket). Data Events: Who accessed the data? (Ex: GetObject S3, Invoke Lambda). Network Activity Events: Monitor VPC network traffic. Automation \u0026amp; Alerting Amazon EventBridge: Real-time Event processing center. Supports Cross-account Event: Receive events from child accounts to the central security account. Automated Alerting: Automatically send alerts when abnormal behavior is detected. Detection as Code: Convert threat detection logic into code (Infrastructure as Code). Use CloudTrail Lake queries to query history. Version control for security rules. Network Security Common Attack Vectors: Common network attack vectors (DDoS, SQL Injection, Man-in-the-middle\u0026hellip;). AWS Layered Security: Defense in Depth strategy - protecting from the outer layer (Edge), network layer (VPC), to application and data layers. What I Learned Modern Security Mindset Identity is the new perimeter: In Cloud environment, identity management (IAM/SSO) is more important than traditional firewalls. Zero Trust: Trust no one, always authenticate (MFA) and grant least privilege. Governance Strategy Shift from Long-term to Short-term: Understand clearly the risks of long-term Access Keys and the importance of shifting to Temporary Credentials. Governance at Scale: Use SCPs to manage hundreds of AWS accounts consistently instead of manual configuration for each. Automation Techniques Event-Driven Security: Instead of manual log review (passive), use EventBridge to react immediately (active) when security incidents occur. Application to Work Review IAM: Check and disable old IAM Access Keys, enforce MFA for the whole team. Deploy Access Analyzer: Activate immediately to scan if any S3 bucket is mistakenly public. Set up alerts: Create simple EventBridge rules to send notifications to Slack/Email when someone logs in with Root account or changes Security Group. Learn about CloudTrail: Configure CloudTrail to record both Management and Data events for critical resources. Event Experience The 3rd event brought a very deep perspective on Security \u0026amp; Governance aspects - an area often overlooked in development but vital for businesses.\nRisk Awareness The presentation on Credentials Spectrum startled me into realizing how dangerous the habit of using IAM Users with Long-term keys is. Shifting to Short-term credentials is mandatory. The Power of Automation I was very impressed with the concept of \u0026ldquo;Detection as Code\u0026rdquo;. Managing security rules like source code helps operations become transparent and easier to control. The EventBridge demo showed excellent real-time response capabilities, minimizing the time attackers can cause harm in the system. Multi-layered Defense Mindset Understood better about AWS Layered Security, security is not just a door but multiple barrier layers coordinating from Network to Identity.\nThis event changed my mindset from \u0026ldquo;Make it run\u0026rdquo; to \u0026ldquo;Make it safe and compliant\u0026rdquo;. Security is not a barrier, but a foundation for sustainable development.\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"My internship at Amazon Web Services Vietnam Co., Ltd. from August 12, 2025 to November 12, 2025 was a transformative period where I applied theoretical knowledge to build scalable, production-grade cloud systems.\nMy primary responsibility involved designing the Solution Architecture based on the AWS Well-Architected Framework and setting up Automated Operations (CI/CD). Through this process, I have rapidly matured my skills in Cloud Engineering, critical analysis, and technical reporting within enterprise environment.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ✅ ☐ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ☐ ✅ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ✅ ☐ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Deepen knowledge of Cloud troubleshooting \u0026amp; system optimization. Improve the ability to explain architectures to others people "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Review academic subjects for the upcoming midterm exam on 31/10/2025. Maintain light progress on the project while prioritizing exam preparation. Revise MVC-related concepts to strengthen understanding for future development. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Create a study plan for midterm exam - Review lecture notes and core concepts 20/10/2025 20/10/2025 3 - Practice midterm exercises and sample questions 21/10/2025 21/10/2025 Practice sheets 4 - Light project review: revise MVC folder structure \u0026amp; check model consistency 22/10/2025 22/10/2025 MVC Documentation 5 - Continue studying for midterm exam 23/10/2025 23/10/2025 6 - Review project documentation and plan next week\u0026rsquo;s development 24/10/2025 24/10/2025 Project documents Week 7 Achievements: Successfully prepared a clear study plan for the upcoming midterm exam on 31/10. Reviewed major subjects and practiced essential exam questions to reinforce understanding. Allocated time efficiently between academic studying and project responsibilities. Completed a light review of the project’s MVC structure, ensuring consistency before returning to full development next week. Organized documentation and outlined tasks to resume development after the exam. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"During the internship, I participated in 6 events. Each event was a memorable experience providing new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: AWS Cloud Day 2025\nTime: 9:00 on Septemper 18, 2025\nLocation: 26th Floor, Bitexco Financial Tower, No. 02 Hai Trieu Street, Sai Gon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: Data Science on AWS Workshop\nTime: 9:30 on October 16, 2025\nLocation: Hall Academic – FPT University\nRole: Attendee\nEvent 3 Event Name: Reinventing DevSecOps with AWS Generative AI\nTime: 19:30 on October 16, 2025\nLocation: Online via Microsoft Teams\nRole: Attendee\nEvent 4 Event Name: AI/ML/GenAI on AWS\nTime: 8:00 on November 15, 2025\nLocation: 26th Floor, Bitexco Financial Tower, No. 02 Hai Trieu Street, Sai Gon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 5 Event Name: DevOps on AWS\nTime: 8:30 on November 17, 2025\nLocation: 26th Floor, Bitexco Financial Tower, No. 02 Hai Trieu Street, Sai Gon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 6 Event Name: AWS Well-Architected Security Pillar\nTime: 8:30 on November 29, 2025\nLocation: 26th Floor, Bitexco Financial Tower, No. 02 Hai Trieu Street, Sai Gon Ward, Ho Chi Minh City\nRole: Attendee\n"},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.7-security/","title":"Optimization &amp; Security","tags":[],"description":"","content":"Resource Cleanup Overview A Production system needs not only to \u0026ldquo;run\u0026rdquo; but also to \u0026ldquo;run fast\u0026rdquo; and be \u0026ldquo;secure\u0026rdquo;. In this part, we will refine the MiniMarket architecture\nImplementation items:\nOffloading Static Assets: Transfer all product images from Web Server to Amazon S3 and distribute via Amazon CloudFront (CDN) to accelerate global page load speed and offload the server Security Hardening: Deploy AWS WAF (Web Application Firewall) in front of CloudFront to protect the application from common attacks such as SQL Injection and XSS Content Configure S3 and CloudFront Set up AWS WAF "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always ready to support me whenever I face difficulties, even outside of working hours. The workspace is tidy and comfortable, which helps me focus better.\n2. Support from Mentor / Team Admin\nThe Team Admin supported me by guiding problem-solving mindsets and creating favorable conditions for me to work effectively.\n3. Relevance of Work to Academic Major\nThe assigned tasks align well with my academic background while allowing me to access modern Cloud technologies that meet enterprise needs. As a result, I have acquired many practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork, and professional communication in a corporate environment. Mentors also shared practical experiences that helped me better orient my career path.\n5. Company Culture \u0026amp; Team Spirit\nThere is mutual respect among everyone. The team maintains a professional attitude when necessary but also knows how to have fun to keep the atmosphere stress-free.\n6. Internship Policies / Benefits\nThe company facilitates interns participation in events to gain new knowledge for project completion, as well as for future application. Additional Questions What did you find most satisfying during your internship? Being facilitated to attend workshops and events to broaden my knowledge. What do you think the company should improve for future interns? Increase direct working time to make technical exchange more effective. If recommending to a friend, would you suggest they intern here? Why or why not? Yes. If my friends want to gain substantial new knowledge, I would suggest they intern here. Suggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? Organize more workshops for further learning. Would you like to continue this program in the future? Yes. Any other comments (free sharing): "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Focus on studying and completing the midterm exam on 31/10. Maintain minimal involvement in the project due to exam week. Review previous project progress in preparation for returning next week. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Final review of midterm subjects - Practice remaining exercises 27/10/2025 27/10/2025 3 - Continue midterm exam preparation 28/10/2025 28/10/2025 Practice sheets 4 - Sit for the midterm exam (31/10) 31/10/2025 31/10/2025 5 - Light project maintenance: verify folders \u0026amp; update small documentation 01/11/2025 01/11/2025 Project documentation 6 - Rest after the exam and prepare to resume full project development next week 02/11/2025 02/11/2025 Week 8 Achievements: Completed the midterm exam on 31/10 successfully after intensive review. Managed time effectively to balance light project maintenance and exam preparation. Updated project documentation and verified folder structures to ensure readiness when returning to development. Maintained academic focus this week while still keeping the project organized and on track. Prepared a plan to resume full development work in Week 9. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.8-monitoring/","title":"Monitoring &amp; Operations","tags":[],"description":"","content":"Overview A Production system cannot be considered complete without Monitoring and Alerting capabilities. You cannot sit watching the screen 24/7 to check if the Server is still alive\nIn this module, we will set up monitoring and alerting for MiniMarket using AWS operations management services:\nAmazon CloudWatch: Collect metrics (Metrics) from EC2, RDS, ELB Amazon SNS (Simple Notification Service): Notification service. We will use it to send Emails to administrators when the system encounters issues We will set up a CloudWatch Alarm to monitor Web Server CPU. If CPU exceeds 70% (sign of overload or attack), the system will automatically trigger SNS to send emergency alert Emails\nContent Set up CloudWatch Alarms \u0026amp; SNS "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Understand ASP.NET Core middleware and filters for request processing. Implement authentication flow using Identity. Manage user sessions and implement \u0026ldquo;Remember Me\u0026rdquo; with cookies. Practice secure login and logout flow. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Study middleware \u0026amp; filters in ASP.NET Core - Learn how UseAuthentication() and UseAuthorization() work 03/11/2025 03/11/2025 Microsoft Docs / Tutorials 3 - Implement Login and Logout functionality using Identity 04/11/2025 04/11/2025 ASP.NET Core Identity Docs 4 - Manage sessions for logged-in users - Store user info in session 05/11/2025 05/11/2025 Tutorials / Sample Code 5 - Implement \u0026ldquo;Remember Me\u0026rdquo; using cookies - Auto-fill login form for returning users 06/11/2025 06/11/2025 ASP.NET Core Cookie Docs 6 - Test full authentication flow - Ensure secure access to protected pages 07/11/2025 07/11/2025 Project code review Week 9 Achievements: Learned how to configure ASP.NET Core middleware and filters for request handling. Implemented user login and logout using Identity with proper session management. Successfully implemented \u0026ldquo;Remember Me\u0026rdquo; functionality with cookies. Tested and verified protected pages could only be accessed by authenticated users. Reviewed and refactored authentication code for better security and maintainability. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/5-workshop/5.9-cleanup/","title":"Resource Cleanup","tags":[],"description":"","content":"Overview Congratulations on successfully deploying MiniMarket on AWS!\nHowever, our work does not end there. The final step and also the most important step to protect your \u0026ldquo;wallet\u0026rdquo; is Resource Cleanup\nThe services we deployed such as NAT Gateway, Elastic Load Balancer, RDS, ElastiCache are all billed by the hour, whether you use them or not. If you forget to delete, the month-end bill can be very high\nWe will go through the system Decommissioning process in the correct order to ensure no resources are left behind causing hidden costs\nContent Safe resource deletion process "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Implement the first CRUD module in the project (e.g., Customer or Product management). Connect MVC Controllers and Views with the database using Entity Framework Core. Apply basic form validation and server-side error handling. Test CRUD functionality to ensure data consistency. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Create Models and DbContext for the module 10/11/2025 10/11/2025 EF Core Documentation 3 - Scaffold Controller and Views for CRUD operations 11/11/2025 11/11/2025 ASP.NET Core Tutorials 4 - Implement Create, Read, Update, Delete functionality in Controller 12/11/2025 12/11/2025 Project Database Schema 5 - Add server-side validation using Data Annotations 13/11/2025 13/11/2025 Microsoft Docs 6 - Attend company event 14/11/2025 14/11/2025 Week 10 Achievements: Successfully implemented the first CRUD module with full Create, Read, Update, Delete operations. Connected Controllers and Views to the database using Entity Framework Core. Applied form validation with Data Annotations, ensuring input correctness. Tested all CRUD functionalities and handled possible exceptions. Prepared the project structure for adding additional modules in the coming weeks. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives: Learn Docker fundamentals and containerization concepts. Build Dockerfile for the ASP.NET Core project. Set up docker-compose with SQL Server for development environment. Test running the project inside Docker and verify database connectivity. Explore Docker volumes and networking for persistence and container communication. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Attend company event\n- Study Docker basics: containers, images, Docker CLI commands 17/11/2025 17/11/2025 Docker Docs / Tutorials 3 - Write Dockerfile for ASP.NET Core project 18/11/2025 18/11/2025 Microsoft Docs / Tutorials 4 - Create docker-compose with ASP.NET Core app and SQL Server container 19/11/2025 19/11/2025 Docker Compose Docs 5 - Build and run containers, test project connectivity and CRUD module 20/11/2025 20/11/2025 Project testing notes 6 - Learn Docker volumes and networking - Ensure database persistence across container restarts 21/11/2025 21/11/2025 Docker Docs Week 11 Achievements: Learned Docker basics, including containers, images, and essential CLI commands. Successfully built Dockerfile for the ASP.NET Core project. Configured docker-compose with SQL Server and ASP.NET Core container. Ran the project inside Docker, verified database connectivity and CRUD operations. Explored Docker volumes and networks to maintain data persistence and container communication. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Objectives: Improve the UI of the project to enhance user experience. Add static product images stored locally for display in the project. Test that images are correctly displayed on product pages and CRUD views. Finalize project layout and prepare documentation for submission. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Fix layout and design of main pages (Dashboard, CRUD pages) 24/11/2025 24/11/2025 Bootstrap / Tailwind Docs 3 - Add static images for products stored in wwwroot/images 25/11/2025 25/11/2025 ASP.NET Core Docs 4 - Update Create, Edit, and Details views to display static images 26/11/2025 26/11/2025 Project code / Tutorials 5 - Test product images display with CRUD functionality 27/11/2025 27/11/2025 Project testing notes 6 - Review UI and project layout, fix minor issues, prepare final documentation 28/11/2025 28/11/2025 Project documentation 7 - Attend company event 29/11/2025 29/11/2025 Company Event Materials Week 12 Achievements: Improved overall UI of the project for better user experience. Added static product images and displayed them correctly on all relevant views. Verified product images display correctly with CRUD operations. Reviewed and refined UI layout, fixed minor design issues. Project ready for final submission with enhanced UI and product image display. "},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://kiethc2710.github.io/AWS_FCJ_Template/tags/","title":"Tags","tags":[],"description":"","content":""}]